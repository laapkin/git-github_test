# Реализация LRU Cache (базовый вариант)

## Требования

* Реализовать структуру данных, которая хранит максимум **N элементов**.
* При желании использовать `Generics` для типов ключа и значения, иначе -> `int` и `string`.
* При добавлении нового элемента, если размер кэша превышает `N`, должен удаляться **самый старый** элемент (наименее недавно использованный элемент).
* Операции:

  1. `Get(key K) (V, bool)` — возвращает значение и `true`, если ключ найден, иначе `zero-value` и `false`. Данная операция делает найденный элемент **самым новым**.
  2. `Put(key K, value V)` — вставляет элемент в кэш. Данная операция делает добавленный элемент **самым новым**.
  3. `Size() int` — возвращает количество элементов в кэше.

## Условия по производительности

* Время работы операций `Get` и `Put` должно быть **O(1)**.

## Проверка

Запроси у ChatGPT тест файл с условиями:

* пакет называет `lru`
* у пакет определены методы:
  * `func New(size int) *LruCache`
  * `func (lc *LruCache) Get(key int) (val string, ok bool)`
  * `func (lc *LruCache) Put(key int, val string)`
  * `func (lc *LruCache) Size() int`
* если используешь дженерики, то:
  * `func[K comparable, V] New(size int) *LruCache[K, V]`
  * `func (lc *LruCache[K, V]) Get(key K) (val V, ok bool)`
  * `func (lc *LruCache[K, V]) Put(key K, val V)`
  * `func (lc *LruCache[K, V]) Size() int`
* Операции `Get` и `Put` имеют амортизированную константную сложность (сопоставима со скоростями `map`)